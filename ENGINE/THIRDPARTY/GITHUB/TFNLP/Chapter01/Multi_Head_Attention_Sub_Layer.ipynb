{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aXACkAtfNpG0"
   },
   "source": [
    "# The Attention Mechanism\n",
    "Copyright 2020, Denis Rothman, MIT License. Denis Rothman rewrote the reference notebook entirely in basic Python with no frameworks. Three more steps were added, and a Hugging Face transformer example was added. The original images were taken out, redesigned by Denis Rothman for educational purposes, and inserted in the book descriptions of the multi-attention sub-layer.\n",
    "\n",
    "[The Reference Colaboratory Notebook was written by Manuel Romero](https://colab.research.google.com/drive/1rPk3ohrmVclqhH7uQ7qys4oznDdAhpzF)\n",
    "\n",
    "[A Medium article was written by Raimi Karim](https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "veRoFjFRNXwJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "JLe9lWCJNogW",
    "outputId": "733e039b-343e-4161-9919-19b3a1ec130f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Input : 3 inputs, d_model=4\n",
      "[[1. 0. 1. 0.]\n",
      " [0. 2. 0. 2.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 1: Input : 3 inputs, d_model=4\")\n",
    "x =np.array([[1.0, 0.0, 1.0, 0.0],   # Input 1\n",
    "             [0.0, 2.0, 0.0, 2.0],   # Input 2\n",
    "             [1.0, 1.0, 1.0, 1.0]])  # Input 3\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "JZImwtHPN91V",
    "outputId": "07706940-e200-4956-b957-fe9681139d0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: weights 3 dimensions x d_model=4\n",
      "w_query\n",
      "[[1 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 2: weights 3 dimensions x d_model=4\")\n",
    "print(\"w_query\")\n",
    "w_query =np.array([[1, 0, 1],\n",
    "                   [1, 0, 0],\n",
    "                   [0, 0, 1],\n",
    "                   [0, 1, 1]])\n",
    "print(w_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "7kRBS7MUOFgV",
    "outputId": "8b0bcc03-88b1-4e8d-a483-dacc91ffa9ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_key\n",
      "[[0 0 1]\n",
      " [1 1 0]\n",
      " [0 1 0]\n",
      " [1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"w_key\")\n",
    "w_key =np.array([[0, 0, 1],\n",
    "                 [1, 1, 0],\n",
    "                 [0, 1, 0],\n",
    "                 [1, 1, 0]])\n",
    "print(w_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "Napm2VtkOIEN",
    "outputId": "7331eb08-64d5-4a36-eeef-0a0a556f130b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_value\n",
      "[[0 2 0]\n",
      " [0 3 0]\n",
      " [1 0 3]\n",
      " [1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"w_value\")\n",
    "w_value = np.array([[0, 2, 0],\n",
    "                    [0, 3, 0],\n",
    "                    [1, 0, 3],\n",
    "                    [1, 1, 0]])\n",
    "print(w_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "JqapIgfDOQ7d",
    "outputId": "fd610d7a-968a-47e6-d614-40ad03c1d172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Matrix multiplication to obtain Q,K,V\n",
      "Queries: x * w_query\n",
      "[[1. 0. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 1. 3.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 3: Matrix multiplication to obtain Q,K,V\")\n",
    "\n",
    "print(\"Queries: x * w_query\")\n",
    "Q=np.matmul(x,w_query)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "NmfMln1Wmv73",
    "outputId": "065b63ba-7584-4302-97cd-d5e1765470ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Matrix multiplication to obtain Q,K,V\n",
      "Keys: x * w_key\n",
      "[[0. 1. 1.]\n",
      " [4. 4. 0.]\n",
      " [2. 3. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 3: Matrix multiplication to obtain Q,K,V\")\n",
    "\n",
    "print(\"Keys: x * w_key\")\n",
    "K=np.matmul(x,w_key)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "v3Asv-8mOWkN",
    "outputId": "2ec71310-0486-46f4-d9f5-d12a1a6ad0e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: x * w_value\n",
      "[[1. 2. 3.]\n",
      " [2. 8. 0.]\n",
      " [2. 6. 3.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Values: x * w_value\")\n",
    "V=np.matmul(x,w_value)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "gfgRAHUuOp5c",
    "outputId": "ad02f055-11e0-4b9a-eb15-b66e4846c95e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Scaled Attention Scores\n",
      "[[ 2.  4.  4.]\n",
      " [ 4. 16. 12.]\n",
      " [ 4. 12. 10.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 4: Scaled Attention Scores\")\n",
    "k_d=1   #square root of k_d=3 rounded down to 1 for this example\n",
    "attention_scores = (Q @ K.transpose())/k_d\n",
    "print(attention_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "hg2t6KuNOjzM",
    "outputId": "c0610f91-cd1d-4b0f-b5ce-f6445481186a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Scaled softmax attention_scores for each vector\n",
      "[0.06337894 0.46831053 0.46831053]\n",
      "[6.03366485e-06 9.82007865e-01 1.79861014e-02]\n",
      "[2.95387223e-04 8.80536902e-01 1.19167711e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 5: Scaled softmax attention_scores for each vector\")\n",
    "attention_scores[0]=softmax(attention_scores[0])\n",
    "attention_scores[1]=softmax(attention_scores[1])\n",
    "attention_scores[2]=softmax(attention_scores[2])\n",
    "print(attention_scores[0])\n",
    "print(attention_scores[1])\n",
    "print(attention_scores[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "R4Es7A7NOvjD",
    "outputId": "b86060fe-1292-47c5-93f6-ddeeca1bfb62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: attention value obtained by score1/k_d * V\n",
      "[1. 2. 3.]\n",
      "[2. 8. 0.]\n",
      "[2. 6. 3.]\n",
      "Attention 1\n",
      "[0.06337894 0.12675788 0.19013681]\n",
      "Attention 2\n",
      "[0.93662106 3.74648425 0.        ]\n",
      "Attention 3\n",
      "[0.93662106 2.80986319 1.40493159]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 6: attention value obtained by score1/k_d * V\")\n",
    "print(V[0])\n",
    "print(V[1])\n",
    "print(V[2])\n",
    "print(\"Attention 1\")\n",
    "attention1=attention_scores[0].reshape(-1,1)\n",
    "attention1=attention_scores[0][0]*V[0]\n",
    "print(attention1)\n",
    "\n",
    "print(\"Attention 2\")\n",
    "attention2=attention_scores[0][1]*V[1]\n",
    "print(attention2)\n",
    "\n",
    "print(\"Attention 3\")\n",
    "attention3=attention_scores[0][2]*V[2]\n",
    "print(attention3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "uBDKhaCvOzXj",
    "outputId": "138901d8-0aa9-4db9-b8b1-76ad557e6688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7: summed the results to create the first line of the output matrix\n",
      "[1.93662106 6.68310531 1.59506841]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 7: summed the results to create the first line of the output matrix\")\n",
    "attention_input1=attention1+attention2+attention3\n",
    "print(attention_input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "colab_type": "code",
    "id": "iEjgRcqHO4ik",
    "outputId": "675a154b-a305-4c0c-e314-353541abfd3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8: Step 1 to 7 for inputs 1 to 3\n",
      "[[0.79183864 0.70920881 0.07896367 0.30759865 0.61305466 0.0633872\n",
      "  0.81533078 0.05708428 0.15922293 0.14193983 0.99110479 0.71098465\n",
      "  0.14932631 0.37455851 0.85432968 0.68055306 0.6381475  0.63047639\n",
      "  0.07830879 0.5894161  0.7433223  0.72058275 0.14514077 0.91892923\n",
      "  0.02317537 0.57754486 0.09058038 0.6629607  0.20933684 0.38076739\n",
      "  0.3018169  0.15712656 0.53718326 0.37927309 0.3035906  0.35419601\n",
      "  0.92989732 0.8287684  0.22847179 0.23312222 0.86245024 0.14564641\n",
      "  0.22692396 0.28177232 0.50242897 0.16925721 0.68764707 0.43261159\n",
      "  0.76155789 0.44566265 0.4361731  0.54157323 0.85435396 0.38735042\n",
      "  0.51509803 0.97729032 0.80158426 0.36797288 0.04003635 0.73701327\n",
      "  0.90342631 0.78191024 0.96173365 0.53371163]\n",
      " [0.04743111 0.51590054 0.13545895 0.47791315 0.92226458 0.53261473\n",
      "  0.61422928 0.8634762  0.64810295 0.05804857 0.69067217 0.84457773\n",
      "  0.08607767 0.86990485 0.12373183 0.97836145 0.37595625 0.63437281\n",
      "  0.00974459 0.0785653  0.55434765 0.51858022 0.52259486 0.23477832\n",
      "  0.57333218 0.69588211 0.1971674  0.2711474  0.13371773 0.58100947\n",
      "  0.11905287 0.18089738 0.67700481 0.1150427  0.53139191 0.81360356\n",
      "  0.90302049 0.59394667 0.9374182  0.00993995 0.88587651 0.7912645\n",
      "  0.87917126 0.00586921 0.93630051 0.45791681 0.34663674 0.22952001\n",
      "  0.74779678 0.22511242 0.42668623 0.78278202 0.17483621 0.02111685\n",
      "  0.67260578 0.5400543  0.94831199 0.21768219 0.42077472 0.97978164\n",
      "  0.53788759 0.65876687 0.13386967 0.30463498]\n",
      " [0.84130785 0.96470981 0.73821461 0.88391415 0.20308887 0.46974372\n",
      "  0.73657712 0.04768684 0.65099827 0.6884709  0.15887063 0.8879577\n",
      "  0.29965815 0.14918585 0.01077641 0.94413631 0.64068123 0.11341671\n",
      "  0.80021903 0.390615   0.67203933 0.93851372 0.3684452  0.66182129\n",
      "  0.6186736  0.64972026 0.0366911  0.52169793 0.82000451 0.30094817\n",
      "  0.09246306 0.0091272  0.84845712 0.87359184 0.37873928 0.97039383\n",
      "  0.80816141 0.99556932 0.88430649 0.14044228 0.57234305 0.95777846\n",
      "  0.57983113 0.47260965 0.79914818 0.25452785 0.42418381 0.9724005\n",
      "  0.21411271 0.59982357 0.11409976 0.35559452 0.78344779 0.6720204\n",
      "  0.50124782 0.9249428  0.07458788 0.78052493 0.54434222 0.60312317\n",
      "  0.08977702 0.84980401 0.21122215 0.67897972]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 8: Step 1 to 7 for inputs 1 to 3\")\n",
    "#We assume we have 3 results with learned weights (they were not trained in this example)\n",
    "#We assume we are implementing the original Transformer paper. We will have 3 results of 64 dimensions each\n",
    "attention_head1=np.random.random((3, 64))\n",
    "print(attention_head1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "QI50dkZ1O630",
    "outputId": "7d467842-f837-4e41-e099-534549b6fc05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9: We assume we have trained the 8 heads of the attention sub-layer\n",
      "shape of one head (3, 64) dimension of 8 heads 512\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 9: We assume we have trained the 8 heads of the attention sub-layer\")\n",
    "z0h1=np.random.random((3, 64))\n",
    "z1h2=np.random.random((3, 64))\n",
    "z2h3=np.random.random((3, 64))\n",
    "z3h4=np.random.random((3, 64))\n",
    "z4h5=np.random.random((3, 64))\n",
    "z5h6=np.random.random((3, 64))\n",
    "z6h7=np.random.random((3, 64))\n",
    "z7h8=np.random.random((3, 64))\n",
    "print(\"shape of one head\",z0h1.shape,\"dimension of 8 heads\",64*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "3n87LE92_Puf",
    "outputId": "55d00415-ebea-43a6-b4c5-ff13e02c3052"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: Concatenation of heads 1 to 8 to obtain the original 8x64=512 output dimension of the model\n",
      "[[0.37948525 0.90541222 0.31783561 ... 0.73220475 0.21625204 0.94830315]\n",
      " [0.5912732  0.53452929 0.30356289 ... 0.57259259 0.17643547 0.44694757]\n",
      " [0.18184253 0.30325067 0.76975345 ... 0.0461338  0.71319833 0.39463988]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 10: Concatenation of heads 1 to 8 to obtain the original 8x64=512 output dimension of the model\")\n",
    "output_attention=np.hstack((z0h1,z1h2,z2h3,z3h4,z4h5,z5h6,z6h7,z7h8))\n",
    "print(output_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PJLl4Jf3fPLh"
   },
   "source": [
    "And now with Hugging Face in one line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZIRvcRmfTPb"
   },
   "outputs": [],
   "source": [
    "#@title Transformer Installation\n",
    "!pip -qq install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "946c90b82f7f46caa25c885668b75eab",
      "4191af78535e4da8bb797690eff84e00",
      "9ce3d57b96b64da0b15e3f3626bacb30",
      "f8da2c91156342a69d9b262f4f993aa4",
      "97370923218945c5b80ab468751ac8a7",
      "0ba4a91f472e4c41ba80ab4025288446",
      "15aa4b6f8f784c74804107be249126b9",
      "edea457617ed4792aeeb65292019ceb4"
     ]
    },
    "colab_type": "code",
    "id": "cNwLYc-SfXdF",
    "outputId": "d1314cc6-74d6-45cf-b8d6-0a903e58ac60"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db7f264f8cd45a986b45231315cae53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1199.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9046df9fe524175b20df1433f65ebfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=891691430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-base were not used when initializing T5Model: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
      "- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc15ce8caebc41e085144b3e8aad7fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=791656.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410f9e63e5d640bd9a78b6ff7a204ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1389353.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': \"Il est facile de traduire des langues à l'aide de transformateurs\"}]\n"
     ]
    }
   ],
   "source": [
    "#@title Retrieve pipeline of modules and choose English to French translation\n",
    "from transformers import pipeline\n",
    "translator = pipeline(\"translation_en_to_fr\")\n",
    "#One line of code!\n",
    "print(translator(\"It is easy to translate languages with transformers\", max_length=40))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Multi-Head Attention Sub-Layer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ba4a91f472e4c41ba80ab4025288446": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15aa4b6f8f784c74804107be249126b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4191af78535e4da8bb797690eff84e00": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "946c90b82f7f46caa25c885668b75eab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9ce3d57b96b64da0b15e3f3626bacb30",
       "IPY_MODEL_f8da2c91156342a69d9b262f4f993aa4"
      ],
      "layout": "IPY_MODEL_4191af78535e4da8bb797690eff84e00"
     }
    },
    "97370923218945c5b80ab468751ac8a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9ce3d57b96b64da0b15e3f3626bacb30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ba4a91f472e4c41ba80ab4025288446",
      "max": 230,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_97370923218945c5b80ab468751ac8a7",
      "value": 230
     }
    },
    "edea457617ed4792aeeb65292019ceb4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8da2c91156342a69d9b262f4f993aa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edea457617ed4792aeeb65292019ceb4",
      "placeholder": "​",
      "style": "IPY_MODEL_15aa4b6f8f784c74804107be249126b9",
      "value": " 230/230 [00:01&lt;00:00, 185B/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

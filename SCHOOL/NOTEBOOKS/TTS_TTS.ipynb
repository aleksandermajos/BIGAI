{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac512ac-f2e7-4e4d-b34a-a63c1e64ec5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TTS.utils.manage.ModelManager object at 0x7f9253d86e10>\n",
      " > You must confirm the following:\n",
      " | > \"I have purchased a commercial license from Coqui: licensing@coqui.ai\"\n",
      " | > \"Otherwise, I agree to the terms of the non-commercial CPML: https://coqui.ai/cpml\" - [y/n]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " | | >  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading model to /home/bigai/.var/app/com.jetbrains.PyCharm-Professional/data/tts/tts_models--multilingual--multi-dataset--xtts_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 1.86G/1.87G [00:21<00:00, 85.7MiB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.87G/1.87G [00:22<00:00, 83.5MiB/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.37k/4.37k [00:00<00:00, 11.0kiB/s]\n",
      " 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 345k/361k [00:00<00:00, 1.27MiB/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361k/361k [00:00<00:00, 480kiB/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32.0/32.0 [00:00<00:00, 52.1iB/s]\n",
      " 73%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                   | 5.70M/7.75M [00:00<00:00, 29.2MiB/s]/home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model's license - CPML\n",
      " > Check https://coqui.ai/cpml.txt for more info.\n",
      " > Using model: xtts\n",
      " > Text splitted to sentences.\n",
      "['Hello world!']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to open the input \"my/cloning/audio.wav\" (No such file or directory).\nException raised from get_input_format_context at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_reader/stream_reader.cpp:42 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f93600dbd87 in /home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f936008c75f in /home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #2: <unknown function> + 0x42904 (0x7f927a3ca904 in /home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torio/lib/libtorio_ffmpeg6.so)\nframe #3: torio::io::StreamingMediaDecoder::StreamingMediaDecoder(std::string const&, std::optional<std::string> const&, std::optional<std::map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<std::string const, std::string> > > > const&) + 0x14 (0x7f927a3cd304 in /home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torio/lib/libtorio_ffmpeg6.so)\nframe #4: <unknown function> + 0x3ab5e (0x7f92738d0b5e in /home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torio/lib/_torio_ffmpeg6.so)\nframe #5: <unknown function> + 0x32737 (0x7f92738c8737 in /home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torio/lib/_torio_ffmpeg6.so)\nframe #6: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x528187]\nframe #7: _PyObject_MakeTpCall + 0x27c (0x503a0c in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #8: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x557009]\nframe #9: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x53fe5e]\nframe #10: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x503e0c]\nframe #11: <unknown function> + 0xf874 (0x7f9284a75874 in /home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torchaudio/lib/_torchaudio.so)\nframe #12: _PyObject_MakeTpCall + 0x27c (0x503a0c in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #13: _PyEval_EvalFrameDefault + 0x6a3 (0x510f33 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #14: _PyFunction_Vectorcall + 0x173 (0x538733 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #15: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x53fad9]\nframe #16: _PyObject_MakeTpCall + 0x243 (0x5039d3 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #17: _PyEval_EvalFrameDefault + 0x6a3 (0x510f33 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #18: _PyFunction_Vectorcall + 0x173 (0x538733 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #19: PyObject_Call + 0x12c (0x5426bc in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #20: _PyEval_EvalFrameDefault + 0x4761 (0x514ff1 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #21: _PyFunction_Vectorcall + 0x173 (0x538733 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #22: PyObject_Call + 0x12c (0x5426bc in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #23: _PyEval_EvalFrameDefault + 0x4761 (0x514ff1 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #24: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x55771f]\nframe #25: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x556f0e]\nframe #26: PyObject_Call + 0x12c (0x5426bc in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #27: _PyEval_EvalFrameDefault + 0x4761 (0x514ff1 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #28: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x55771f]\nframe #29: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x556f0e]\nframe #30: PyObject_Call + 0x12c (0x5426bc in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #31: _PyEval_EvalFrameDefault + 0x4761 (0x514ff1 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #32: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x55771f]\nframe #33: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x556f0e]\nframe #34: PyObject_Call + 0x12c (0x5426bc in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #35: _PyEval_EvalFrameDefault + 0x4761 (0x514ff1 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #36: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5cb55a]\nframe #37: PyEval_EvalCode + 0x9f (0x5cac2f in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #38: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5e43d3]\nframe #39: _PyEval_EvalFrameDefault + 0x3585 (0x513e15 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #40: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #41: _PyEval_EvalFrameDefault + 0x327e (0x513b0e in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #42: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #43: _PyEval_EvalFrameDefault + 0x327e (0x513b0e in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #44: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #45: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5e2446]\nframe #46: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x540b0b]\nframe #47: PyObject_Vectorcall + 0x31 (0x51e0b1 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #48: _PyEval_EvalFrameDefault + 0x6a3 (0x510f33 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #49: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x55771f]\nframe #50: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x556f0e]\nframe #51: PyObject_Call + 0x12c (0x5426bc in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #52: _PyEval_EvalFrameDefault + 0x4761 (0x514ff1 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #53: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #54: _PyEval_EvalFrameDefault + 0x327e (0x513b0e in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #55: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #56: _PyEval_EvalFrameDefault + 0x327e (0x513b0e in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #57: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #58: _PyEval_EvalFrameDefault + 0x327e (0x513b0e in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #59: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #60: _PyEval_EvalFrameDefault + 0x327e (0x513b0e in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #61: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #62: _PyEval_EvalFrameDefault + 0x327e (0x513b0e in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #63: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m tts \u001b[38;5;241m=\u001b[39m TTS(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtts_models/multilingual/multi-dataset/xtts_v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Run TTS\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ❗ Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Text to speech list of amplitude values as output\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m wav \u001b[38;5;241m=\u001b[39m \u001b[43mtts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello world!\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy/cloning/audio.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Text to speech to a file\u001b[39;00m\n\u001b[1;32m     18\u001b[0m tts\u001b[38;5;241m.\u001b[39mtts_to_file(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello world!\u001b[39m\u001b[38;5;124m\"\u001b[39m, speaker_wav\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy/cloning/audio.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m, file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/PycharmProjects/TTS/TTS/api.py:276\u001b[0m, in \u001b[0;36mTTS.tts\u001b[0;34m(self, text, speaker, language, speaker_wav, emotion, speed, split_sentences, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert text to speech.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m        Additional arguments for the model.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_arguments(\n\u001b[1;32m    274\u001b[0m     speaker\u001b[38;5;241m=\u001b[39mspeaker, language\u001b[38;5;241m=\u001b[39mlanguage, speaker_wav\u001b[38;5;241m=\u001b[39mspeaker_wav, emotion\u001b[38;5;241m=\u001b[39memotion, speed\u001b[38;5;241m=\u001b[39mspeed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    275\u001b[0m )\n\u001b[0;32m--> 276\u001b[0m wav \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlanguage_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstyle_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstyle_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference_speaker_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_sentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_sentences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wav\n",
      "File \u001b[0;32m~/PycharmProjects/TTS/TTS/utils/synthesizer.py:386\u001b[0m, in \u001b[0;36mSynthesizer.tts\u001b[0;34m(self, text, speaker_name, language_name, speaker_wav, style_wav, style_text, reference_wav, reference_speaker_name, split_sentences, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sens:\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynthesize\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 386\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspeaker_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvoice_dirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvoice_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43md_vector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;66;03m# synthesize voice\u001b[39;00m\n\u001b[1;32m    398\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m synthesis(\n\u001b[1;32m    399\u001b[0m             model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_model,\n\u001b[1;32m    400\u001b[0m             text\u001b[38;5;241m=\u001b[39msen,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    408\u001b[0m             language_id\u001b[38;5;241m=\u001b[39mlanguage_id,\n\u001b[1;32m    409\u001b[0m         )\n",
      "File \u001b[0;32m~/PycharmProjects/TTS/TTS/tts/models/xtts.py:419\u001b[0m, in \u001b[0;36mXtts.synthesize\u001b[0;34m(self, text, config, speaker_wav, language, speaker_id, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(text, language, gpt_cond_latent, speaker_embedding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings)\n\u001b[1;32m    413\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt_cond_len\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mgpt_cond_len,\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt_cond_chunk_len\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mgpt_cond_chunk_len,\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_ref_len\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mmax_ref_len,\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msound_norm_refs\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39msound_norm_refs,\n\u001b[1;32m    418\u001b[0m })\n\u001b[0;32m--> 419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/TTS/TTS/tts/models/xtts.py:480\u001b[0m, in \u001b[0;36mXtts.full_inference\u001b[0;34m(self, text, ref_audio_path, language, temperature, length_penalty, repetition_penalty, top_k, top_p, do_sample, gpt_cond_len, gpt_cond_chunk_len, max_ref_len, sound_norm_refs, **hf_generate_kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39minference_mode()\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfull_inference\u001b[39m(\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_generate_kwargs,\n\u001b[1;32m    440\u001b[0m ):\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    This function produces an audio clip of the given text being spoken with the given reference voice.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m        Sample rate is 24kHz.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m     (gpt_cond_latent, speaker_embedding) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_conditioning_latents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43maudio_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_audio_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgpt_cond_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpt_cond_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgpt_cond_chunk_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpt_cond_chunk_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_ref_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ref_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43msound_norm_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msound_norm_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(\n\u001b[1;32m    489\u001b[0m         text,\n\u001b[1;32m    490\u001b[0m         language,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_generate_kwargs,\n\u001b[1;32m    500\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/TTS/TTS/tts/models/xtts.py:357\u001b[0m, in \u001b[0;36mXtts.get_conditioning_latents\u001b[0;34m(self, audio_path, max_ref_length, gpt_cond_len, gpt_cond_chunk_len, librosa_trim_db, sound_norm_refs, load_sr)\u001b[0m\n\u001b[1;32m    355\u001b[0m speaker_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m audio_paths:\n\u001b[0;32m--> 357\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_sr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m     audio \u001b[38;5;241m=\u001b[39m audio[:, : load_sr \u001b[38;5;241m*\u001b[39m max_ref_length]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sound_norm_refs:\n",
      "File \u001b[0;32m~/PycharmProjects/TTS/TTS/tts/models/xtts.py:73\u001b[0m, in \u001b[0;36mload_audio\u001b[0;34m(audiopath, sampling_rate)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_audio\u001b[39m(audiopath, sampling_rate):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# better load setting following: https://github.com/faroit/python_audio_loading_benchmark\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# torchaudio should chose proper backend to load audio depending on platform\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     audio, lsr \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudiopath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m# stereo to mono if needed\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m audio\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torchaudio/_backend/utils.py:205\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torchaudio/_backend/ffmpeg.py:297\u001b[0m, in \u001b[0;36mFFmpegBackend.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m    289\u001b[0m     uri: InputType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m     buffer_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m,\n\u001b[1;32m    296\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torchaudio/_backend/ffmpeg.py:88\u001b[0m, in \u001b[0;36mload_audio\u001b[0;34m(src, frame_offset, num_frames, convert, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(src, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvorbis\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mogg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 88\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStreamReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m sample_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(s\u001b[38;5;241m.\u001b[39mget_src_stream_info(s\u001b[38;5;241m.\u001b[39mdefault_audio_stream)\u001b[38;5;241m.\u001b[39msample_rate)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;241m=\u001b[39m _get_load_filter(frame_offset, num_frames, convert)\n",
      "File \u001b[0;32m~/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torio/io/_streaming_media_decoder.py:526\u001b[0m, in \u001b[0;36mStreamingMediaDecoder.__init__\u001b[0;34m(self, src, format, option, buffer_size)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_be \u001b[38;5;241m=\u001b[39m ffmpeg_ext\u001b[38;5;241m.\u001b[39mStreamingMediaDecoderFileObj(src, \u001b[38;5;28mformat\u001b[39m, option, buffer_size)\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_be \u001b[38;5;241m=\u001b[39m \u001b[43mffmpeg_ext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStreamingMediaDecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_be\u001b[38;5;241m.\u001b[39mfind_best_audio_stream()\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_audio_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m i\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to open the input \"my/cloning/audio.wav\" (No such file or directory).\nException raised from get_input_format_context at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_reader/stream_reader.cpp:42 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f93600dbd87 in /home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f936008c75f in /home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #2: <unknown function> + 0x42904 (0x7f927a3ca904 in /home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torio/lib/libtorio_ffmpeg6.so)\nframe #3: torio::io::StreamingMediaDecoder::StreamingMediaDecoder(std::string const&, std::optional<std::string> const&, std::optional<std::map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<std::string const, std::string> > > > const&) + 0x14 (0x7f927a3cd304 in /home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torio/lib/libtorio_ffmpeg6.so)\nframe #4: <unknown function> + 0x3ab5e (0x7f92738d0b5e in /home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torio/lib/_torio_ffmpeg6.so)\nframe #5: <unknown function> + 0x32737 (0x7f92738c8737 in /home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torio/lib/_torio_ffmpeg6.so)\nframe #6: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x528187]\nframe #7: _PyObject_MakeTpCall + 0x27c (0x503a0c in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #8: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x557009]\nframe #9: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x53fe5e]\nframe #10: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x503e0c]\nframe #11: <unknown function> + 0xf874 (0x7f9284a75874 in /home/bigai/anaconda3/envs/BIGAI/lib/python3.11/site-packages/torchaudio/lib/_torchaudio.so)\nframe #12: _PyObject_MakeTpCall + 0x27c (0x503a0c in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #13: _PyEval_EvalFrameDefault + 0x6a3 (0x510f33 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #14: _PyFunction_Vectorcall + 0x173 (0x538733 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #15: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x53fad9]\nframe #16: _PyObject_MakeTpCall + 0x243 (0x5039d3 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #17: _PyEval_EvalFrameDefault + 0x6a3 (0x510f33 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #18: _PyFunction_Vectorcall + 0x173 (0x538733 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #19: PyObject_Call + 0x12c (0x5426bc in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #20: _PyEval_EvalFrameDefault + 0x4761 (0x514ff1 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #21: _PyFunction_Vectorcall + 0x173 (0x538733 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #22: PyObject_Call + 0x12c (0x5426bc in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #23: _PyEval_EvalFrameDefault + 0x4761 (0x514ff1 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #24: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x55771f]\nframe #25: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x556f0e]\nframe #26: PyObject_Call + 0x12c (0x5426bc in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #27: _PyEval_EvalFrameDefault + 0x4761 (0x514ff1 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #28: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x55771f]\nframe #29: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x556f0e]\nframe #30: PyObject_Call + 0x12c (0x5426bc in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #31: _PyEval_EvalFrameDefault + 0x4761 (0x514ff1 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #32: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x55771f]\nframe #33: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x556f0e]\nframe #34: PyObject_Call + 0x12c (0x5426bc in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #35: _PyEval_EvalFrameDefault + 0x4761 (0x514ff1 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #36: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5cb55a]\nframe #37: PyEval_EvalCode + 0x9f (0x5cac2f in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #38: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5e43d3]\nframe #39: _PyEval_EvalFrameDefault + 0x3585 (0x513e15 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #40: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #41: _PyEval_EvalFrameDefault + 0x327e (0x513b0e in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #42: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #43: _PyEval_EvalFrameDefault + 0x327e (0x513b0e in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #44: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #45: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5e2446]\nframe #46: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x540b0b]\nframe #47: PyObject_Vectorcall + 0x31 (0x51e0b1 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #48: _PyEval_EvalFrameDefault + 0x6a3 (0x510f33 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #49: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x55771f]\nframe #50: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x556f0e]\nframe #51: PyObject_Call + 0x12c (0x5426bc in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #52: _PyEval_EvalFrameDefault + 0x4761 (0x514ff1 in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #53: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #54: _PyEval_EvalFrameDefault + 0x327e (0x513b0e in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #55: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #56: _PyEval_EvalFrameDefault + 0x327e (0x513b0e in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #57: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #58: _PyEval_EvalFrameDefault + 0x327e (0x513b0e in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #59: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #60: _PyEval_EvalFrameDefault + 0x327e (0x513b0e in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #61: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\nframe #62: _PyEval_EvalFrameDefault + 0x327e (0x513b0e in /home/bigai/anaconda3/envs/BIGAI/bin/python)\nframe #63: /home/bigai/anaconda3/envs/BIGAI/bin/python() [0x5dfdea]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.75M/7.75M [00:15<00:00, 29.2MiB/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# List available 🐸TTS models\n",
    "print(TTS().list_models())\n",
    "\n",
    "# Init TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "# Run TTS\n",
    "# ❗ Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language\n",
    "# Text to speech list of amplitude values as output\n",
    "wav = tts.tts(text=\"Hello world!\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\")\n",
    "# Text to speech to a file\n",
    "tts.tts_to_file(text=\"Hello world!\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\", file_path=\"output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233abe66-e506-4233-9065-252e7c445837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
